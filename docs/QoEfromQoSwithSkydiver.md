---


---

<h1 id="estimating-client-satisfaction-qoe-from-server-side-network-qos-metrics">Estimating Client Satisfaction (QoE) from Server Side Network QoS metrics</h1>
<h2 id="overview">Overview:</h2>
<p>The objective of this PoC is to demonstrate the ability to estimate QoE, as perceived by the user, by applying cognitive methods to analyse network-level metrics collected by the service provider. The assumption is that the service provider can measure various QoS metrics; however, does not have full information on the actual QoE that the user is experiencing. Therefore, it must estimate the QoE from the measured QoS metrics. We employ machine learning (ML) to learn the QoS relationship to QoE through training with labelled examples. The learned data can be utilized at run-time to predict probable SLA violations and trigger corrective measures.</p>
<p>This approach is intended to be integrated into the <a href="https://slicenet.eu/5g-ehealth-smart-connected-ambulance-use-case/">SliceNet eHealth UC</a> and exercises several SliceNet workflows; including, E2E service cognition, monitoring, and QoE feedback. The PoC is focused on the QoE KPI of E2E latency.<br>
Following the SliceNet data-driven operations approach, the model is deployed as part of the slice to generate an Estimated-QoE metric from monitored QoS KPIs. This metric is then consumed by slice control functions to trigger control and/or management actions required for proactively maintaining the service-level QoE, before any degradation affects the user.</p>
<p>This article emphasizes the role <a href="http://skydive.network/">Skydive</a> plays in gathering QoS data and the transformations required to make its data useful input to the ML algorithm.</p>
<h2 id="poc-experiment-setup-and-implementation-details">PoC experiment setup and Implementation details:</h2>
<p>The PoC experiment setup is described in the Figure at <a href="https://drive.google.com/file/d/142FpFA_BjYh2hIZU3qlv67ibOoEdbxKe/view">https://drive.google.com/file/d/142FpFA_BjYh2hIZU3qlv67ibOoEdbxKe/view</a>.<br>
<img src="https://drive.google.com/file/d/1ctToSj5UmealPQYWIpbeQJbMzQK1I4sS/view?usp=sharing" alt=""><br>
We use a web service (WordPress) and measure the service level from the client perspective.  The application is created on two <a href="https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/">Kubernetes (K8s)</a> container clouds deployed through the <a href="https://www.ibm.com/cloud/private">IBM Cloud Private (ICP)</a> service; the wordpress client is on one cluster and the wordpress server is running on the other cluster.<br>
Kubernetes (K8s) Cluster 2 corresponds to a managed slice, where the slice provider collects QoS metrics (through Skydive) in order to manage the slice QoE. Stresser nodes running iperf3 clients generate controlled traffic to vary the E2E service behaviour; namely the QoE of the client. Actual service-level E2E QoE metrics are collected (by test diver) and provided by the vertical (service user) for model training and validation. A ML classification process learns a QoE sensor model that estimates E2E QoE from measured QoS metrics. The model is then validated.</p>
<p>In order to simulate the user’s workload, an application to generate WordPress client traffic to our WordPress service is run. The WordPress Client load is created with the <a href="https://blog.kubernauts.io/load-testing-as-a-service-with-jmeter-on-kubernetes-fc5288bb0c8b">Load Testing With Jmeter On Kubernetes and OpenShift</a> tool. Our <a href="https://github.com/KennethNagin/slicenet/blob/master/src/test_driver.py">test driver</a> utility was designed to coordinate the running of the WordPress client workloads, referred to as benchmark instances, concurrently with various levels of stress generated by <a href="https://github.com/esnet/iperf">iperf3</a>. The test driver also maintains an index that records the start time, end time, benchmark duration of each experimental sample used to map the benchmark duration (QoE) to the Skydive flows (QoS). The WordPress client benchmark consists of multiple concurrent downloads of the two files, 5MB and 15MB, from  the WordPress Server. The downloads are done with HTTP Keep-Alive set to false. In the background various levels of stress are run including no stress.<br>
Skydive is used to collect network flow metrics (QoS). We directed Skydive to capture network flow metrics on the WordPress service interface, i.e. eth0.  The Test Driver’s Index and Skydive flows are copied to an <a href="https://www.ibm.com/cloud/object-storage?cm_mmc=Search_Google-_-Hybrid%20Cloud_Cloud%20Platform%20Digital-_-WW_ISP-_-ibm%20cloud%20object%20storage_e&amp;cm_mmca1=000016GC&amp;cm_mmca2=10007090&amp;cm_mmca7=20519&amp;cm_mmca8=aud-311016886972:kwd-320507222281&amp;cm_mmca9=_k_CjwKCAjw44jrBRAHEiwAZ9igKMxu3y3BI1Uttyj3yggyLtJL_KmtGmgGvTTWYRLCesHRbVtV4fhjIhoCqnAQAvD_BwE_k_&amp;cm_mmca10=376202091526&amp;cm_mmca11=e&amp;gclsrc=aw.ds&amp;&amp;gclid=CjwKCAjw44jrBRAHEiwAZ9igKMxu3y3BI1Uttyj3yggyLtJL_KmtGmgGvTTWYRLCesHRbVtV4fhjIhoCqnAQAvD_BwE">IBM Cloud Object Store (COS)</a>.<br>
Analysis of the data is done in an <a href="https://cloud.ibm.com/catalog/services/watson-studio">IBM Watson Studio</a> notebook with a Python 3.6 kernel. The <a href="https://pandas.pydata.org/">Python Data Analysis Library (Pandas)</a> is used to aggregate the QoS and QoE measures. Finally, the <a href="https://scikit-learn.org/stable/">Python Scikit-learn</a> library is used for creating the ML models.</p>
<h2 id="scenario">Scenario</h2>
<p>The PoC comes in two phases 1) Benchmark execution and data collection 2) ML analysis.</p>
<h3 id="benchmark-execution-and-data-collection">Benchmark execution and data collection:</h3>
<ol>
<li>Measuring QoE – in order to develop our approach, we created a controlled environment, where we measure both the server side network QoS measures and application-level client QoE, i.e. benchmark duration.</li>
<li>Generating different quality of experiences – we generate “other” network traffic to the host on which the subject benchmark is running using iperf3 udp traffic. Multiple iperf3 servers are running on the same host as the WordPress server, while the iperf3 clients are launched on nodes other than the WordPress client.  The iperf3 clients are run concurrently with the WordPress benchmarks.  Various noise levels are generating by varying the number of client threads (-P), number of bytes transferred (-b), and  number running clients (one client per node).</li>
<li>Measuring QoS – under our simulation model assumptions, the slice service provider can only measure local metrics within its slice. In our environment, we limited the QoS measurements to the K8s cluster that runs the WordPress service; namely, there are no metrics from the client cluster. The QoS is derived from network flows captured by Skydive on the interface belonging to the WordPress service.<br>
This is the python code to create the capture network traffic to/from the WordPress service:</li>
</ol>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">from</span> skydive<span class="token punctuation">.</span>rest<span class="token punctuation">.</span>client <span class="token keyword">import</span> RESTClient
<span class="token keyword">import</span> yaml
conf_vars <span class="token operator">=</span> yaml<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'tests_conf.yaml'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
SKYDIVE_IP<span class="token operator">=</span>conf_vars<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'skydive_ip'</span><span class="token punctuation">,</span> <span class="token string">'9.148.244.26'</span><span class="token punctuation">)</span>
SKYDIVE_PORT<span class="token operator">=</span>conf_vars<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'skydive_port'</span><span class="token punctuation">,</span> <span class="token string">'30777'</span><span class="token punctuation">)</span>
restclient <span class="token operator">=</span> RESTClient<span class="token punctuation">(</span>SKYDIVE_IP<span class="token operator">+</span><span class="token string">":"</span><span class="token operator">+</span>SKYDIVE_PORT<span class="token punctuation">)</span>
restclient<span class="token punctuation">.</span>capture_create<span class="token punctuation">(</span><span class="token string">"G.V().Has('Manager', NE('k8s'),'Docker.Labels.app', Regex('.*wordpress.*'),'Docker.Labels.tier', Regex('frontend')).Both().Out('Name','eth0')"</span><span class="token punctuation">)</span>
</code></pre>
<p>The capture code can be found in <a href="https://github.com/KennethNagin/slicenet/blob/master/src/capture_wp1.py">capture_wp.py</a>.<br>
The Skydive flow capture api is used to capture the actual flows in real time. It is invoked by our <a href="https://github.com/KennethNagin/slicenet/blob/master/src/test_driver.py">test driver</a>. This is the python code used to collect the TCP flows resulting from the above capture:</p>
<pre class=" language-python"><code class="prism  language-python"><span class="token keyword">class</span> <span class="token class-name">threadGetSkydiveFlows</span><span class="token punctuation">(</span>threading<span class="token punctuation">.</span>Thread<span class="token punctuation">)</span><span class="token punctuation">:</span>
   <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
      threading<span class="token punctuation">.</span>Thread<span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>self<span class="token punctuation">)</span>
      self<span class="token punctuation">.</span>collectFlows <span class="token operator">=</span> <span class="token boolean">True</span>
      self<span class="token punctuation">.</span>_return <span class="token operator">=</span> <span class="token punctuation">(</span>pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token string">""</span><span class="token punctuation">)</span>
   <span class="token keyword">def</span> <span class="token function">run</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
      logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"thread threadGetSkydiveFlows starttime %d"</span><span class="token punctuation">,</span><span class="token builtin">int</span><span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">1000.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
      err <span class="token operator">=</span> <span class="token string">""</span>
      restclient <span class="token operator">=</span> RESTClient<span class="token punctuation">(</span>SKYDIVE_IP<span class="token operator">+</span><span class="token string">":"</span><span class="token operator">+</span>SKYDIVE_PORT<span class="token punctuation">)</span>
      gremlinFlow <span class="token operator">=</span> <span class="token string">"G.Flows().Has('Application', 'TCP')"</span>
      flows <span class="token operator">=</span> restclient<span class="token punctuation">.</span>lookup<span class="token punctuation">(</span>gremlinFlow<span class="token punctuation">)</span>
      dfOldFlows <span class="token operator">=</span> json_normalize<span class="token punctuation">(</span>flows<span class="token punctuation">)</span>
      frames <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
      time_out <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> TIME_OUT
      <span class="token keyword">while</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>collectFlows<span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> time_out<span class="token punctuation">)</span><span class="token punctuation">:</span>
	    flows <span class="token operator">=</span> restclient<span class="token punctuation">.</span>lookup<span class="token punctuation">(</span>gremlinFlow<span class="token punctuation">)</span>
	    df <span class="token operator">=</span> json_normalize<span class="token punctuation">(</span>flows<span class="token punctuation">)</span>
	    <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">not</span> df<span class="token punctuation">.</span>empty<span class="token punctuation">)</span> <span class="token operator">&amp;</span> <span class="token punctuation">(</span><span class="token operator">not</span> dfOldFlows<span class="token punctuation">.</span>empty<span class="token punctuation">)</span><span class="token punctuation">:</span>
	    	cond <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'UUID'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>isin<span class="token punctuation">(</span>dfOldFlows<span class="token punctuation">[</span><span class="token string">'UUID'</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token boolean">True</span>
	    	df<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>df<span class="token punctuation">[</span>cond<span class="token punctuation">]</span><span class="token punctuation">.</span>index<span class="token punctuation">,</span> inplace <span class="token operator">=</span> <span class="token boolean">True</span><span class="token punctuation">)</span>
	    <span class="token keyword">if</span> <span class="token operator">not</span> df<span class="token punctuation">.</span>empty<span class="token punctuation">:</span>
		frames<span class="token punctuation">.</span>append<span class="token punctuation">(</span>df<span class="token punctuation">)</span>
	    sleep<span class="token punctuation">(</span>SKYDIVE_SLEEP_TIME<span class="token punctuation">)</span>
      <span class="token keyword">if</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;=</span> time_out<span class="token punctuation">:</span>
	     err <span class="token operator">=</span> <span class="token string">"Error: skydive time out"</span>
	     logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span>err<span class="token punctuation">)</span>         
      df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">)</span> 
      <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>frames<span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">:</span>
        df <span class="token operator">=</span> pd<span class="token punctuation">.</span>concat<span class="token punctuation">(</span>frames<span class="token punctuation">,</span>sort<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
        df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop_duplicates<span class="token punctuation">(</span><span class="token punctuation">)</span>
        df <span class="token operator">=</span> df<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span><span class="token string">"Metric.Last"</span><span class="token punctuation">,</span>ascending<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
        df <span class="token operator">=</span> df<span class="token punctuation">.</span>drop_duplicates<span class="token punctuation">(</span>subset<span class="token operator">=</span><span class="token string">"UUID"</span><span class="token punctuation">,</span> keep<span class="token operator">=</span><span class="token string">'last'</span><span class="token punctuation">)</span>
      self<span class="token punctuation">.</span>_return <span class="token operator">=</span> <span class="token punctuation">(</span>df<span class="token punctuation">,</span>err<span class="token punctuation">)</span>
   <span class="token keyword">def</span> <span class="token function">join</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
      sleep<span class="token punctuation">(</span>SKYDIVE_SLEEP<span class="token punctuation">)</span> 
      self<span class="token punctuation">.</span>collectFlows <span class="token operator">=</span> <span class="token boolean">False</span> 
      Thread<span class="token punctuation">.</span>join<span class="token punctuation">(</span>self<span class="token punctuation">)</span>
      <span class="token keyword">return</span> self<span class="token punctuation">.</span>_return
</code></pre>
<p>The code collection code (above) is a thread that runs concurrently with the benchmark instance.  The problem that it needs to be solved is to collect only the most recent flows for the current benchmark,  but flows from the previous benchmark are mixed in with fiows from the current benchmark and flows with the same UUID are being updated over time.  The tactic to solve this problem is to transforms the Skydive flows into pandas dataframes.  The gremlin expression indicates that it is only interested in TCP flows. It then gets residual flows from the previous benchmark.   In the loop it gets new flows from the current benchmark and removes the residual flows from the previous benchmark. When the benchmark instance completes the test driver joins the Skydive thread which toggles the collectionFlows flag which in turn breaks the loop. After completing its loop the code concatenates all the flows that it collected, removes duplicates, and uses only the most recent flow identified by its UUID.</p>
<ol start="4">
<li>Labeling -   The QoE and QoS flows are labelled with the benchmark instance ID when they were captured. The labelled data is stored as csv files in IBM’s Cloud Object Store for ML analysis.</li>
</ol>
<h3 id="ml-analysis">ML Analysis</h3>
<ol>
<li>Data Input - The ML analysis is done in an IBM Watson Studio python 3.6 notebook. The CSV files created in the first phase are read into the notebook.</li>
<li>Transformations - The labelled Skydive flows are transformed into pandas dataframes for use by the ML algorithms.  Additional per flow transformation  were required, as listed below:</li>
</ol>
<ul>
<li>flow_duration:  Metric.Last - Metric.Start</li>
<li>bytes_per_flow: Metric.ABBytes + Metric.BABytes) / flow_duration</li>
<li>packets_per_flow: Metric.ABPackets + Metric.BAPackets / 'flow_duration</li>
<li>AB_bytes_per_flow:  Metric.ABBytes / flow_duration</li>
<li>BA_bytes_per_flow: Metric.BABytes  / flow_duration</li>
<li>AB_packets_per_flow: Metric.ABPackets / flow_duration</li>
<li>BA_packets_per_flow: Metric.BAPackets  / flow_duration</li>
<li>RTT:  Metric.RTT</li>
</ul>
<ol start="3">
<li>Aggregations:  The above transformations are then aggregated into per benchmark instance mean values; these mean values are used as QoS features for the ML training and testing sets. <a href="#ML-QoS-Features">see ML QoS Features</a></li>
<li>Training Set – QoS features from each benchmark instance are matched against the target QoE benchmark instance durations.  A validation set is created in a similar way.</li>
<li>Learning – We apply classification ML (both Binary and Multiclass) to infer the measured QoE class from the transformed SkyDive metrics.</li>
<li>Model Validation – The model is validated against the validation set.</li>
</ol>
<h2 id="ml-results">ML Results</h2>
<p>The PoC’s ML evaluation properties are outlined below:</p>
<ul>
<li>Establish threshold boundaries to be used in the classification by examining the QoE measurments</li>
<li>Evaluate for both Binary Classification and Multiclass Classification</li>
<li>Evaluate with all of the ML classifiers</li>
<li>Evaluate with all of combinations of QoS Features</li>
<li>Compare the evaluation methods (classifier and feature combination) and determine the best performers</li>
</ul>
<h3 id="ml-target-qoe">ML Target QoE</h3>
<p>The target QoE used in the evaluation was the workload duration recorded by the test driver.</p>
<h3 id="ml-qos-features">ML QoS Features</h3>
<p>The following QoS features were used in the evaluation:</p>
<ul>
<li>flow_duration_mean</li>
<li>bytes_per_flow_mean</li>
<li>packets_per_flow_mean</li>
<li>AB_bytes_per_flow_mean</li>
<li>BA_bytes_per_flow_mean</li>
<li>AB_packets_per_flow_mean</li>
<li>BA_packets_per_flow_mean</li>
<li>RTT_mean</li>
</ul>
<p>All combinations of the above features are exercised to determine which should be used by the classifiers described below to best predict the target QoE.</p>
<h3 id="ml-classifiers">ML Classifiers</h3>
<p>Different scikit classifiers were used in the analysis.  The classifiers are compared to determine which best predicts the target QoE using QoS features described above.<br>
The following classifiers are used in the evaluation:</p>
<ul>
<li>LogisticRegression</li>
<li>DecisionTreeClassifier</li>
<li>KNeighborsClassifier</li>
<li>LinearDiscriminantAnalysis</li>
<li>RandomForestClassifier</li>
<li>GaussianNB</li>
<li>SVC</li>
<li>MLPClassifier  (removed because it was taking too long)</li>
<li>GaussianProcessClassifier(removed because it was taking too long)</li>
<li>AdaBoostClassifier</li>
<li>QuadraticDiscriminantAnalysis</li>
</ul>
<h3 id="ml-conclusion">ML Conclusion</h3>
<p>The QuadraticDiscriminantAnalysis Classifier is the best classifier for both Binary Classification and MultiClass Classification.<br>
The table below summarizes the results:</p>
<ul>
<li>training set 1266</li>
<li>testing set 203</li>
</ul>

<table>
<thead>
<tr>
<th>Classification</th>
<th align="center">Classifier</th>
<th align="center">features</th>
<th align="center">f1_score</th>
<th align="right">accuracy_score</th>
<th align="right">log_loss_score</th>
</tr>
</thead>
<tbody>
<tr>
<td>binary</td>
<td align="center">QuadraticDiscriminantAnalysis</td>
<td align="center">flow_duration_mean<br>bytes_per_flow_mean<br>packets_per_flow_mean<br>BA_bytes_per_flow_mean<br>AB_packets_per_flow_mean<br>RTT_mean</td>
<td align="center">.921</td>
<td align="right">.921</td>
<td align="right">.199</td>
</tr>
<tr>
<td>multiclass</td>
<td align="center">QuadraticDiscriminantAnalysis</td>
<td align="center">flow_duration_mean<br>bytes_per_flow_mean<br>packets_per_flow_mean<br>AB_bytes_per_flow_mean<br>BA_bytes_per_flow_mean<br>BA_packets_per_flow_mean</td>
<td align="center">.833</td>
<td align="right">.833</td>
<td align="right">.415</td>
</tr>
</tbody>
</table>
